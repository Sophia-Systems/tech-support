# === Ports ===
# Change these if the defaults conflict with existing services
API_PORT=8000
FRONTEND_PORT=3000
LANGFUSE_PORT=3100
POSTGRES_PORT=5432
REDIS_PORT=6379

# === Infrastructure ===
POSTGRES_DB=customer_service_bot
POSTGRES_USER=csbot
POSTGRES_PASSWORD=changeme

REDIS_URL=redis://localhost:6379/0

# === LLM ===
# LiteLLM supports 100+ providers. Prefix model name accordingly.
# OpenAI: gpt-4o, gpt-4o-mini
# Anthropic: anthropic/claude-sonnet-4-20250514
# AWS Bedrock: bedrock/anthropic.claude-sonnet-4-20250514-v1:0
LLM_MODEL=anthropic/claude-sonnet-4-20250514
LLM_API_KEY=your-api-key-here

# === Embeddings ===
EMBEDDING_PROVIDER=sentence-transformers
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_API_KEY=
EMBEDDING_DIMENSION=384

# === Reranker ===
RERANKER_PROVIDER=cross-encoder
RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# === Vector Store ===
VECTORSTORE_PROVIDER=pgvector

# === LangFuse (observability â€” optional) ===
LANGFUSE_PUBLIC_KEY=
LANGFUSE_SECRET_KEY=
LANGFUSE_HOST=http://localhost:3100

# === Escalation ===
ESCALATION_WEBHOOK_URL=https://hooks.example.com/escalation

# === App ===
APP_ENV=production
APP_DEBUG=false
APP_LOG_LEVEL=INFO
APP_CORS_ORIGINS=["http://localhost:3000"]
